[{"path":"https://marklhc.github.io/plavaan/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2025 Hok Chio (Mark) Lai Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":[]},{"path":"https://marklhc.github.io/plavaan/articles/penalized-fa.html","id":"two-factor-cfa-model","dir":"Articles","previous_headings":"Penalize cross-loadings","what":"Two-factor CFA model","title":"Penalized Estimation of Cross-Loadings and Unique Covariances","text":"","code":"mod0 <- \"   ind60 =~ x1 + x2 + x3   dem60 =~ y1 + y2 + y3 + y4   ind60 ~~ dem60 \" fit0 <- cfa(mod0, data = PoliticalDemocracy, std.lv = TRUE)"},{"path":"https://marklhc.github.io/plavaan/articles/penalized-fa.html","id":"two-factor-efa-model-unidentified","dir":"Articles","previous_headings":"Penalize cross-loadings","what":"Two-factor EFA model (unidentified)","title":"Penalized Estimation of Cross-Loadings and Unique Covariances","text":"","code":"mod <- \"   ind60 =~ x1 + x2 + x3 + y1 + y2 + y3 + y4   dem60 =~ x1 + x2 + x3 + y1 + y2 + y3 + y4   ind60 ~~ ind60 \" fit <- cfa(mod, data = PoliticalDemocracy, std.lv = TRUE, do.fit = FALSE)"},{"path":"https://marklhc.github.io/plavaan/articles/penalized-fa.html","id":"two-factor-efa-model-with-penalized-cross-loadings","dir":"Articles","previous_headings":"Penalize cross-loadings","what":"Two-factor EFA model with penalized cross-loadings","title":"Penalized Estimation of Cross-Loadings and Unique Covariances","text":"cross-loadings parameters 4 10 parameter table (see free column).","code":"parTable(fit) #>    id   lhs op   rhs user block group free ustart exo label plabel start   est #> 1   1 ind60 =~    x1    1     1     1    1     NA   0         .p1. 0.951 0.951 #> 2   2 ind60 =~    x2    1     1     1    2     NA   0         .p2. 2.001 2.001 #> 3   3 ind60 =~    x3    1     1     1    3     NA   0         .p3. 1.687 1.687 #> 4   4 ind60 =~    y1    1     1     1    4     NA   0         .p4. 1.344 1.344 #> 5   5 ind60 =~    y2    1     1     1    5     NA   0         .p5. 1.807 1.807 #> 6   6 ind60 =~    y3    1     1     1    6     NA   0         .p6. 1.778 1.778 #> 7   7 ind60 =~    y4    1     1     1    7     NA   0         .p7. 2.256 2.256 #> 8   8 dem60 =~    x1    1     1     1    8     NA   0         .p8. 0.951 0.951 #> 9   9 dem60 =~    x2    1     1     1    9     NA   0         .p9. 2.001 2.001 #> 10 10 dem60 =~    x3    1     1     1   10     NA   0        .p10. 1.687 1.687 #> 11 11 dem60 =~    y1    1     1     1   11     NA   0        .p11. 1.344 1.344 #> 12 12 dem60 =~    y2    1     1     1   12     NA   0        .p12. 1.807 1.807 #> 13 13 dem60 =~    y3    1     1     1   13     NA   0        .p13. 1.778 1.778 #> 14 14 dem60 =~    y4    1     1     1   14     NA   0        .p14. 2.256 2.256 #> 15 15 ind60 ~~ ind60    1     1     1    0      1   0        .p15. 1.000 1.000 #> 16 16    x1 ~~    x1    0     1     1   15     NA   0        .p16. 0.265 0.265 #> 17 17    x2 ~~    x2    0     1     1   16     NA   0        .p17. 1.126 1.126 #> 18 18    x3 ~~    x3    0     1     1   17     NA   0        .p18. 0.975 0.975 #> 19 19    y1 ~~    y1    0     1     1   18     NA   0        .p19. 3.393 3.393 #> 20 20    y2 ~~    y2    0     1     1   19     NA   0        .p20. 7.686 7.686 #> 21 21    y3 ~~    y3    0     1     1   20     NA   0        .p21. 5.310 5.310 #> 22 22    y4 ~~    y4    0     1     1   21     NA   0        .p22. 5.535 5.535 #> 23 23 dem60 ~~ dem60    0     1     1    0      1   0        .p23. 1.000 1.000 #> 24 24 ind60 ~~ dem60    0     1     1   22     NA   0        .p24. 0.000 0.000 pefa_fit <- penalized_est(     fit,     w = .03,     pen_par_id = 4:10 ) summary(pefa_fit) #> lavaan 0.6-20 ended normally after 126 iterations #>  #>   Estimator                                         ML #>   Optimization method                           NLMINB #>   Number of model parameters                        22 #>  #>   Number of observations                            75 #>  #>  #> Parameter Estimates: #>  #>  #> Latent Variables: #>                    Estimate #>   ind60 =~                  #>     x1                0.658 #>     x2                1.456 #>     x3                1.222 #>     y1               -0.007 #>     y2               -0.608 #>     y3               -0.001 #>     y4                0.006 #>   dem60 =~                  #>     x1                0.025 #>     x2               -0.002 #>     x3               -0.010 #>     y1                2.071 #>     y2                3.290 #>     y3                2.256 #>     y4                2.999 #>  #> Covariances: #>                    Estimate #>   ind60 ~~                  #>     dem60             0.481 #>  #> Variances: #>                    Estimate #>     ind60             1.000 #>    .x1                0.079 #>    .x2                0.127 #>    .x3                0.464 #>    .y1                2.493 #>    .y2                6.048 #>    .y3                5.512 #>    .y4                2.017 #>     dem60             1.000"},{"path":[]},{"path":"https://marklhc.github.io/plavaan/articles/penalized-fa.html","id":"two-factor-efa-model-with-unique-covariances","dir":"Articles","previous_headings":"Penalize Cross-loadings and Unique Covariances","what":"Two-factor EFA model with unique covariances","title":"Penalized Estimation of Cross-Loadings and Unique Covariances","text":"","code":"mod2 <- \"   ind60 =~ x1 + x2 + x3 + y1 + y2 + y3 + y4   dem60 =~ x1 + x2 + x3 + y1 + y2 + y3 + y4   ind60 ~~ ind60   x1 ~~ x2 + x3 + y1 + y2 + y3 + y4   x2 ~~ x3 + y1 + y2 + y3 + y4   x3 ~~ y1 + y2 + y3 + y4   y1 ~~ y2 + y3 + y4   y2 ~~ y3 + y4   y3 ~~ y4 \" fit2 <- cfa(mod2, data = PoliticalDemocracy, std.lv = TRUE, do.fit = FALSE)"},{"path":"https://marklhc.github.io/plavaan/articles/penalized-fa.html","id":"two-factor-efa-model-with-penalized-cross-loadings-and-unique-covariances","dir":"Articles","previous_headings":"Penalize Cross-loadings and Unique Covariances","what":"Two-factor EFA model with penalized cross-loadings and unique covariances","title":"Penalized Estimation of Cross-Loadings and Unique Covariances","text":"unique covariances parameters 15 35 parameter table (see free column). unique covariances estimated close zero. One can approximate “effective” number cross-loadings unique covariances : 28 parameters penalized, 1.6 (close 2) effectively non-zero.","code":"parTable(fit2) #>    id   lhs op   rhs user block group free ustart exo label plabel start   est #> 1   1 ind60 =~    x1    1     1     1    1     NA   0         .p1. 0.951 0.951 #> 2   2 ind60 =~    x2    1     1     1    2     NA   0         .p2. 2.001 2.001 #> 3   3 ind60 =~    x3    1     1     1    3     NA   0         .p3. 1.687 1.687 #> 4   4 ind60 =~    y1    1     1     1    4     NA   0         .p4. 1.344 1.344 #> 5   5 ind60 =~    y2    1     1     1    5     NA   0         .p5. 1.807 1.807 #> 6   6 ind60 =~    y3    1     1     1    6     NA   0         .p6. 1.778 1.778 #> 7   7 ind60 =~    y4    1     1     1    7     NA   0         .p7. 2.256 2.256 #> 8   8 dem60 =~    x1    1     1     1    8     NA   0         .p8. 0.951 0.951 #> 9   9 dem60 =~    x2    1     1     1    9     NA   0         .p9. 2.001 2.001 #> 10 10 dem60 =~    x3    1     1     1   10     NA   0        .p10. 1.687 1.687 #> 11 11 dem60 =~    y1    1     1     1   11     NA   0        .p11. 1.344 1.344 #> 12 12 dem60 =~    y2    1     1     1   12     NA   0        .p12. 1.807 1.807 #> 13 13 dem60 =~    y3    1     1     1   13     NA   0        .p13. 1.778 1.778 #> 14 14 dem60 =~    y4    1     1     1   14     NA   0        .p14. 2.256 2.256 #> 15 15 ind60 ~~ ind60    1     1     1    0      1   0        .p15. 1.000 1.000 #> 16 16    x1 ~~    x2    1     1     1   15     NA   0        .p16. 0.000 0.000 #> 17 17    x1 ~~    x3    1     1     1   16     NA   0        .p17. 0.000 0.000 #> 18 18    x1 ~~    y1    1     1     1   17     NA   0        .p18. 0.000 0.000 #> 19 19    x1 ~~    y2    1     1     1   18     NA   0        .p19. 0.000 0.000 #> 20 20    x1 ~~    y3    1     1     1   19     NA   0        .p20. 0.000 0.000 #> 21 21    x1 ~~    y4    1     1     1   20     NA   0        .p21. 0.000 0.000 #> 22 22    x2 ~~    x3    1     1     1   21     NA   0        .p22. 0.000 0.000 #> 23 23    x2 ~~    y1    1     1     1   22     NA   0        .p23. 0.000 0.000 #> 24 24    x2 ~~    y2    1     1     1   23     NA   0        .p24. 0.000 0.000 #> 25 25    x2 ~~    y3    1     1     1   24     NA   0        .p25. 0.000 0.000 #> 26 26    x2 ~~    y4    1     1     1   25     NA   0        .p26. 0.000 0.000 #> 27 27    x3 ~~    y1    1     1     1   26     NA   0        .p27. 0.000 0.000 #> 28 28    x3 ~~    y2    1     1     1   27     NA   0        .p28. 0.000 0.000 #> 29 29    x3 ~~    y3    1     1     1   28     NA   0        .p29. 0.000 0.000 #> 30 30    x3 ~~    y4    1     1     1   29     NA   0        .p30. 0.000 0.000 #> 31 31    y1 ~~    y2    1     1     1   30     NA   0        .p31. 0.000 0.000 #> 32 32    y1 ~~    y3    1     1     1   31     NA   0        .p32. 0.000 0.000 #> 33 33    y1 ~~    y4    1     1     1   32     NA   0        .p33. 0.000 0.000 #> 34 34    y2 ~~    y3    1     1     1   33     NA   0        .p34. 0.000 0.000 #> 35 35    y2 ~~    y4    1     1     1   34     NA   0        .p35. 0.000 0.000 #> 36 36    y3 ~~    y4    1     1     1   35     NA   0        .p36. 0.000 0.000 #> 37 37    x1 ~~    x1    0     1     1   36     NA   0        .p37. 0.265 0.265 #> 38 38    x2 ~~    x2    0     1     1   37     NA   0        .p38. 1.126 1.126 #> 39 39    x3 ~~    x3    0     1     1   38     NA   0        .p39. 0.975 0.975 #> 40 40    y1 ~~    y1    0     1     1   39     NA   0        .p40. 3.393 3.393 #> 41 41    y2 ~~    y2    0     1     1   40     NA   0        .p41. 7.686 7.686 #> 42 42    y3 ~~    y3    0     1     1   41     NA   0        .p42. 5.310 5.310 #> 43 43    y4 ~~    y4    0     1     1   42     NA   0        .p43. 5.535 5.535 #> 44 44 dem60 ~~ dem60    0     1     1    0      1   0        .p44. 1.000 1.000 #> 45 45 ind60 ~~ dem60    0     1     1   43     NA   0        .p45. 0.000 0.000 pefa_fit2 <- penalized_est(     fit2,     w = .03,     pen_par_id = c(4:10, 15:35) ) summary(pefa_fit2) #> lavaan 0.6-20 ended normally after 195 iterations #>  #>   Estimator                                         ML #>   Optimization method                           NLMINB #>   Number of model parameters                        43 #>  #>   Number of observations                            75 #>  #>  #> Parameter Estimates: #>  #>  #> Latent Variables: #>                    Estimate #>   ind60 =~                  #>     x1                0.665 #>     x2                1.449 #>     x3                1.225 #>     y1                0.003 #>     y2               -0.005 #>     y3                0.003 #>     y4                0.455 #>   dem60 =~                  #>     x1                0.020 #>     x2                0.001 #>     x3               -0.012 #>     y1                2.119 #>     y2                3.018 #>     y3                2.307 #>     y4                2.743 #>  #> Covariances: #>                    Estimate #>  .x1 ~~                     #>    .x2               -0.004 #>    .x3               -0.009 #>    .y1                0.054 #>    .y2               -0.050 #>    .y3                0.001 #>    .y4                0.018 #>  .x2 ~~                     #>    .x3                0.006 #>    .y1               -0.002 #>    .y2                0.005 #>    .y3                0.010 #>    .y4               -0.012 #>  .x3 ~~                     #>    .y1               -0.010 #>    .y2                0.003 #>    .y3               -0.008 #>    .y4                0.006 #>  .y1 ~~                     #>    .y2               -0.002 #>    .y3                0.012 #>    .y4               -0.009 #>  .y2 ~~                     #>    .y3               -0.006 #>    .y4                0.008 #>  .y3 ~~                     #>    .y4               -0.003 #>   ind60 ~~                  #>     dem60             0.391 #>  #> Variances: #>                    Estimate #>     ind60             1.000 #>    .x1                0.069 #>    .x2                0.143 #>    .x3                0.454 #>    .y1                2.193 #>    .y2                6.148 #>    .y3                5.246 #>    .y4                2.295 #>     dem60             1.000 pen_ests <- as.numeric(coef(pefa_fit2)[c(4:10, 15:35)]) sum(l0a(pen_ests)) #> [1] 1.564463"},{"path":"https://marklhc.github.io/plavaan/articles/penalized-fa.html","id":"penalize-cross-loadings-unique-covariances-and-difference-in-loadings-and-intercepts-across-time","dir":"Articles","previous_headings":"","what":"Penalize Cross-Loadings, Unique Covariances, and Difference in Loadings and Intercepts Across Time","title":"Penalized Estimation of Cross-Loadings and Unique Covariances","text":"First, model without cross-loadings concurrent unique covariances Parameter IDs: (Concurrent) Cross-loadings: 4 10 (Concurrent) Unique covariances: 35 55 Loadings across time: 11 18 Intercepts across time: 27 34 can compute “effective” number cross-loadings unique covariances non-zero: “effective” number loadings intercepts differ across time:","code":"mod3 <- \"     ind60 =~ NA * x1 + x2 + x3     dem60 =~ NA * l1 * y1 + l2 * y2 + l3 * y3 + l4 * y4     dem65 =~ NA * l1 * y5 + l2 * y6 + l3 * y7 + l4 * y8     dem60 ~ ind60     dem65 ~ ind60 + dem60     ind60 ~~ 1 * ind60     dem60 ~~ 1 * dem60     dem65 ~~ NA * dem65     ind60 ~ 0 * 1     dem60 ~ 0 * 1     dem65 ~ NA * 1     x1 + x2 + x3 ~ NA * 1     y1 ~ i1 * 1     y2 ~ i2 * 1     y3 ~ i3 * 1     y4 ~ i4 * 1     y5 ~ i1 * 1     y6 ~ i2 * 1     y7 ~ i3 * 1     y8 ~ i4 * 1     y1 ~~ y5     y2 ~~ y6     y3 ~~ y7     y4 ~~ y8 \" fit3_base <- cfa(mod3, data = PoliticalDemocracy) # Lavaan example of Political Democracy mod3_un <- \"     ind60 =~ NA * x1 + x2 + x3 + y1 + y2 + y3 + y4     dem60 =~ NA * x1 + x2 + x3 + y1 + y2 + y3 + y4     dem65 =~ NA * y5 + y6 + y7 + y8     dem60 ~ ind60     dem65 ~ ind60 + dem60     ind60 ~~ 1 * ind60     dem60 ~~ 1 * dem60     dem65 ~~ NA * dem65     ind60 ~ 0 * 1     dem60 ~ 0 * 1     dem65 ~ NA * 1     x1 + x2 + x3 + y1 + y2 + y3 + y4 ~ NA * 1     y5 + y6 + y7 + y8 ~ NA * 1     x1 ~~ x2 + x3 + y1 + y2 + y3 + y4     x2 ~~ x3 + y1 + y2 + y3 + y4     x3 ~~ y1 + y2 + y3 + y4     y1 ~~ y2 + y3 + y4     y2 ~~ y3 + y4     y3 ~~ y4     y1 ~~ y5     y2 ~~ y6     y3 ~~ y7     y4 ~~ y8 \" fit3 <- cfa(     mod3_un,     data = PoliticalDemocracy,     do.fit = FALSE,     start = fit3_base ) pt3 <- parTable(fit3) # Provide better starting values pt3$start[c(4:10, 35:55)] <- 0 fit3_2 <- lavaan::cfa(     pt3,     data = PoliticalDemocracy,     do.fit = FALSE ) pefa_fit3 <- penalized_est(     fit3_2,     w = .03,     pen_par_id = c(4:10, 35:55),     pen_diff_id = list(         loadings = rbind(11:14, 15:18),         intercepts = rbind(27:30, 31:34)     ) ) #> Warning in trans(x): NaNs produced summary(pefa_fit3, standardized = TRUE) #> lavaan 0.6-20 ended normally after 219 iterations #>  #>   Estimator                                         ML #>   Optimization method                           NLMINB #>   Number of model parameters                        70 #>  #>   Number of observations                            75 #>  #>  #> Parameter Estimates: #>  #>  #> Latent Variables: #>                    Estimate   Std.lv  Std.all #>   ind60 =~                                    #>     x1                0.753    0.753    1.038 #>     x2                1.660    1.660    1.108 #>     x3                1.421    1.421    1.020 #>     y1               -0.001   -0.001   -0.000 #>     y2               -0.001   -0.001   -0.000 #>     y3                0.479    0.479    0.141 #>     y4                0.623    0.623    0.191 #>   dem60 =~                                    #>     x1                0.574    0.702    0.967 #>     x2                1.205    1.473    0.983 #>     x3                0.983    1.202    0.863 #>     y1                1.772    2.167    0.836 #>     y2                2.446    2.992    0.763 #>     y3                2.205    2.697    0.796 #>     y4                2.572    3.145    0.965 #>   dem65 =~                                    #>     y5                1.768    1.992    0.772 #>     y6                2.439    2.747    0.801 #>     y7                2.250    2.535    0.798 #>     y8                2.535    2.856    0.875 #>  #> Regressions: #>                    Estimate   Std.lv  Std.all #>   dem60 ~                                     #>     ind60            -0.704   -0.576   -0.576 #>   dem65 ~                                     #>     ind60             0.316    0.281    0.281 #>     dem60             1.005    1.091    1.091 #>  #> Covariances: #>                    Estimate   Std.lv  Std.all #>  .x1 ~~                                       #>    .x2                0.001    0.001    0.008 #>    .x3               -0.007   -0.007   -0.037 #>    .y1                0.024    0.024    0.062 #>    .y2               -0.040   -0.040   -0.057 #>    .y3                0.006    0.006    0.010 #>    .y4                0.015    0.015    0.034 #>  .x2 ~~                                       #>    .x3                0.001    0.001    0.004 #>    .y1               -0.009   -0.009   -0.016 #>    .y2                0.009    0.009    0.009 #>    .y3                0.006    0.006    0.007 #>    .y4               -0.010   -0.010   -0.017 #>  .x3 ~~                                       #>    .y1               -0.006   -0.006   -0.007 #>    .y2                0.002    0.002    0.001 #>    .y3               -0.010   -0.010   -0.007 #>    .y4                0.009    0.009    0.008 #>  .y1 ~~                                       #>    .y2               -0.008   -0.008   -0.002 #>    .y3                0.011    0.011    0.003 #>    .y4               -0.009   -0.009   -0.004 #>  .y2 ~~                                       #>    .y3               -0.004   -0.004   -0.001 #>    .y4                0.010    0.010    0.002 #>  .y3 ~~                                       #>    .y4                0.000    0.000    0.000 #>  .y1 ~~                                       #>    .y5                0.902    0.902    0.387 #>  .y2 ~~                                       #>    .y6                1.594    1.594    0.307 #>  .y3 ~~                                       #>    .y7                1.257    1.257    0.281 #>  .y4 ~~                                       #>    .y8                0.175    0.175    0.069 #>  #> Intercepts: #>                    Estimate   Std.lv  Std.all #>     ind60             0.000    0.000    0.000 #>    .dem60             0.000    0.000    0.000 #>    .dem65            -0.235   -0.208   -0.208 #>    .x1                5.072    5.072    6.990 #>    .x2                4.820    4.820    3.216 #>    .x3                3.584    3.584    2.572 #>    .y1                5.458    5.458    2.106 #>    .y2                3.764    3.764    0.960 #>    .y3                6.628    6.628    1.956 #>    .y4                4.503    4.503    1.381 #>    .y5                5.464    5.464    2.118 #>    .y6                3.748    3.748    1.093 #>    .y7                6.633    6.633    2.089 #>    .y8                4.510    4.510    1.381 #>  #> Variances: #>                    Estimate   Std.lv  Std.all #>     ind60             1.000    1.000    1.000 #>    .dem60             1.000    0.668    0.668 #>    .dem65             0.106    0.084    0.084 #>    .x1                0.076    0.076    0.144 #>    .x2                0.137    0.137    0.061 #>    .x3                0.445    0.445    0.229 #>    .y1                2.017    2.017    0.300 #>    .y2                6.413    6.413    0.417 #>    .y3                5.473    5.473    0.476 #>    .y4                2.601    2.601    0.245 #>    .y5                2.690    2.690    0.404 #>    .y6                4.211    4.211    0.358 #>    .y7                3.653    3.653    0.362 #>    .y8                2.503    2.503    0.235 pen_ests2 <- as.numeric(coef(pefa_fit3)[c(4:10, 35:55)]) sum(l0a(pen_ests2)) #> [1] 5.1989 ld_ests <- as.numeric(coef(pefa_fit3)[11:18]) int_ests <- as.numeric(coef(pefa_fit3)[27:34]) ld_mat <- matrix(ld_ests, nrow = 2, byrow = TRUE) int_mat <- matrix(int_ests, nrow = 2, byrow = TRUE) composite_pair_loss(ld_mat, fun = l0a) +     composite_pair_loss(int_mat, fun = l0a) #> [1] 0.3263673"},{"path":"https://marklhc.github.io/plavaan/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Hok Chio (Mark) Lai. Author, maintainer.","code":""},{"path":"https://marklhc.github.io/plavaan/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Lai H (2025). plavaan: Penalized estimation latent variable models 'lavaan'. R package version 0.0.0.9000, https://marklhc.github.io/plavaan/.","code":"@Manual{,   title = {plavaan: Penalized estimation for latent variable models with 'lavaan'},   author = {Hok Chio (Mark) Lai},   year = {2025},   note = {R package version 0.0.0.9000},   url = {https://marklhc.github.io/plavaan/}, }"},{"path":"https://marklhc.github.io/plavaan/index.html","id":"plavaan","dir":"","previous_headings":"","what":"Penalized estimation for latent variable models with lavaan","title":"Penalized estimation for latent variable models with lavaan","text":"goal plavaan perform penalized estimation latent variable models using lavaan differentiable penalty function, described Robitzsch (2023) similar approach described Asparouhov & Muthén (2024).","code":""},{"path":"https://marklhc.github.io/plavaan/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Penalized estimation for latent variable models with lavaan","text":"can install development version plavaan like :","code":"# install.packages(\"remotes\") remotes::install_github(\"marklhc/plavaan\")"},{"path":"https://marklhc.github.io/plavaan/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"Penalized estimation for latent variable models with lavaan","text":"basic example obtain penalized cross-loadings confirmatory factor analysis model: Sandwich estimates standard errors can obtained using se = \"robust.huber.white\" argument penalized_est(), unclear valid presence penalization.","code":"library(lavaan) #> This is lavaan 0.6-20 #> lavaan is FREE software! Please report any bugs. library(plavaan) data(HolzingerSwineford1939) model <- '   visual =~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9   textual =~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9   speed =~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 '  # Dry-run to get starting values for the initial un-identified model fit_dry <- cfa(model, data = HolzingerSwineford1939, std.lv = TRUE, do.fit = FALSE)  # Locate the cross-loadings to be penalized from the parameter table pt <- parTable(fit_dry) subset(pt, op == \"=~\") #>    id     lhs op rhs user block group free ustart exo label plabel start   est #> 1   1  visual =~  x1    1     1     1    1     NA   0         .p1. 0.815 0.815 #> 2   2  visual =~  x2    1     1     1    2     NA   0         .p2. 0.515 0.515 #> 3   3  visual =~  x3    1     1     1    3     NA   0         .p3. 0.592 0.592 #> 4   4  visual =~  x4    1     1     1    4     NA   0         .p4. 0.680 0.680 #> 5   5  visual =~  x5    1     1     1    5     NA   0         .p5. 0.769 0.769 #> 6   6  visual =~  x6    1     1     1    6     NA   0         .p6. 0.687 0.687 #> 7   7  visual =~  x7    1     1     1    7     NA   0         .p7. 0.315 0.315 #> 8   8  visual =~  x8    1     1     1    8     NA   0         .p8. 0.335 0.335 #> 9   9  visual =~  x9    1     1     1    9     NA   0         .p9. 0.521 0.521 #> 10 10 textual =~  x1    1     1     1   10     NA   0        .p10. 0.815 0.815 #> 11 11 textual =~  x2    1     1     1   11     NA   0        .p11. 0.515 0.515 #> 12 12 textual =~  x3    1     1     1   12     NA   0        .p12. 0.592 0.592 #> 13 13 textual =~  x4    1     1     1   13     NA   0        .p13. 0.680 0.680 #> 14 14 textual =~  x5    1     1     1   14     NA   0        .p14. 0.769 0.769 #> 15 15 textual =~  x6    1     1     1   15     NA   0        .p15. 0.687 0.687 #> 16 16 textual =~  x7    1     1     1   16     NA   0        .p16. 0.315 0.315 #> 17 17 textual =~  x8    1     1     1   17     NA   0        .p17. 0.335 0.335 #> 18 18 textual =~  x9    1     1     1   18     NA   0        .p18. 0.521 0.521 #> 19 19   speed =~  x1    1     1     1   19     NA   0        .p19. 0.815 0.815 #> 20 20   speed =~  x2    1     1     1   20     NA   0        .p20. 0.515 0.515 #> 21 21   speed =~  x3    1     1     1   21     NA   0        .p21. 0.592 0.592 #> 22 22   speed =~  x4    1     1     1   22     NA   0        .p22. 0.680 0.680 #> 23 23   speed =~  x5    1     1     1   23     NA   0        .p23. 0.769 0.769 #> 24 24   speed =~  x6    1     1     1   24     NA   0        .p24. 0.687 0.687 #> 25 25   speed =~  x7    1     1     1   25     NA   0        .p25. 0.315 0.315 #> 26 26   speed =~  x8    1     1     1   26     NA   0        .p26. 0.335 0.335 #> 27 27   speed =~  x9    1     1     1   27     NA   0        .p27. 0.521 0.521  # Fit the penalized model using plavaan::penalized_est() fit_pen <- penalized_est(   fit_dry,   w = 0.01,  # close to a BIC-like weight for penalty   pen_par_id = c(4:12, 16:24),  # cross-loadings id in the free column   pen_fn = \"l0a\"  # approximate L0 penalty ) summary(fit_pen) #> lavaan 0.6-20 ended normally after 113 iterations #>  #>   Estimator                                         ML #>   Optimization method                           NLMINB #>   Number of model parameters                        39 #>  #>   Number of observations                           301 #>  #>  #> Parameter Estimates: #>  #>  #> Latent Variables: #>                    Estimate #>   visual =~                 #>     x1                0.813 #>     x2                0.545 #>     x3                0.825 #>     x4                0.015 #>     x5               -0.057 #>     x6                0.036 #>     x7               -0.043 #>     x8                0.034 #>     x9                0.382 #>   textual =~                #>     x1                0.029 #>     x2               -0.012 #>     x3               -0.205 #>     x4                0.975 #>     x5                1.137 #>     x6                0.889 #>     x7                0.016 #>     x8               -0.009 #>     x9               -0.010 #>   speed =~                  #>     x1                0.011 #>     x2               -0.028 #>     x3                0.007 #>     x4               -0.004 #>     x5                0.003 #>     x6                0.002 #>     x7                0.698 #>     x8                0.773 #>     x9                0.460 #>  #> Covariances: #>                    Estimate #>   visual ~~                 #>     textual           0.481 #>     speed             0.282 #>   textual ~~                #>     speed             0.203 #>  #> Variances: #>                    Estimate #>    .x1                0.658 #>    .x2                1.091 #>    .x3                0.701 #>    .x4                0.378 #>    .x5                0.412 #>    .x6                0.364 #>    .x7                0.701 #>    .x8                0.408 #>    .x9                0.558 #>     visual            1.000 #>     textual           1.000 #>     speed             1.000"},{"path":"https://marklhc.github.io/plavaan/reference/composite_pair_loss.html","id":null,"dir":"Reference","previous_headings":"","what":"Composite Pairwise Loss Function — composite_pair_loss","title":"Composite Pairwise Loss Function — composite_pair_loss","text":"Computes total loss across pairwise combinations rows matrix.","code":""},{"path":"https://marklhc.github.io/plavaan/reference/composite_pair_loss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Composite Pairwise Loss Function — composite_pair_loss","text":"","code":"composite_pair_loss(x, fun, trans = identity, rescale = \"df\", ...)"},{"path":"https://marklhc.github.io/plavaan/reference/composite_pair_loss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Composite Pairwise Loss Function — composite_pair_loss","text":"x numeric vector, matrix, data frame. matrix, coerced one applying transformation function. fun function compute loss pairwise difference. package supports alignment loss (alf) approximate L0 penalty (l0a), users can provide custom functions well. trans transformation function apply x computing pairwise differences. Default identity (transformation). rescale Either \"df\" (default) rescale total loss degrees freedom (number rows - 1), numeric value (likely 0 1) multiply total loss . ... Additional arguments passed loss function fun.","code":""},{"path":"https://marklhc.github.io/plavaan/reference/composite_pair_loss.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Composite Pairwise Loss Function — composite_pair_loss","text":"numeric scalar representing sum losses across pairwise combinations rows.","code":""},{"path":"https://marklhc.github.io/plavaan/reference/composite_pair_loss.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Composite Pairwise Loss Function — composite_pair_loss","text":"function works : Applying transformation function trans input x Converting result matrix Generating possible pairwise combinations row indices Computing difference pair rows Applying loss function fun difference Summing individual losses","code":""},{"path":"https://marklhc.github.io/plavaan/reference/composite_pair_loss.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Composite Pairwise Loss Function — composite_pair_loss","text":"","code":"# Example with a simple matrix x <- matrix(runif(12), nrow = 4) composite_pair_loss(x, fun = alf) #> [1] 5.148134  # Example with log transformation and L2 loss composite_pair_loss(x, fun = function(x) x^2, trans = log) #> [1] 36.73551"},{"path":"https://marklhc.github.io/plavaan/reference/loss.html","id":null,"dir":"Reference","previous_headings":"","what":"Loss functions — loss","title":"Loss functions — loss","text":"small eps provides smooth, numerically stable approximation |x|^(1/2) (.e. square root absolute value). function vectorized x.","code":""},{"path":"https://marklhc.github.io/plavaan/reference/loss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Loss functions — loss","text":"","code":"alf(x, eps = 0.001)  l0a(x, eps = 0.01)"},{"path":"https://marklhc.github.io/plavaan/reference/loss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Loss functions — loss","text":"x Numeric vector. Input values transform. eps Positive numeric scalar (default .001 alf() .01 l0a()). Small regularization constant avoid non-differentiability division--zero issues.","code":""},{"path":"https://marklhc.github.io/plavaan/reference/loss.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Loss functions — loss","text":"Numeric vector length x.","code":""},{"path":"https://marklhc.github.io/plavaan/reference/loss.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Loss functions — loss","text":"ALF, (x^2 + eps)^(1/4), useful smooth surrogate sqrt(|x|) required (optimization regularization) maintaining numerical stability near x = 0. L0a, x^2/(x^2 + eps), approximation L0 penalty.","code":""},{"path":"https://marklhc.github.io/plavaan/reference/loss.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Loss functions — loss","text":"","code":"alf(0) #> [1] 0.1778279 alf(c(-4, -1, 0, 1, 4)) #> [1] 2.0000312 1.0002499 0.1778279 1.0002499 2.0000312 alf(0.5, eps = 1e-6) #> [1] 0.7071075 l0a(0) #> [1] 0 l0a(c(0, 1e-3, 0.1, 1)) #> [1] 0.00000000 0.00009999 0.50000000 0.99009901 l0a(c(-2, 0, 2), eps = 1e-4) #> [1] 0.999975 0.000000 0.999975"},{"path":"https://marklhc.github.io/plavaan/reference/penalized_est.html","id":null,"dir":"Reference","previous_headings":"","what":"Penalized Parameter Estimation for Longitudinal CFA Models — penalized_est","title":"Penalized Parameter Estimation for Longitudinal CFA Models — penalized_est","text":"Performs penalized estimation lavaan model object optimizing penalized objective function. function extracts objective function lavaan model, applies penalty function specified parameters pairwise differences parameters, returns updated model optimized parameter estimates.","code":""},{"path":"https://marklhc.github.io/plavaan/reference/penalized_est.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Penalized Parameter Estimation for Longitudinal CFA Models — penalized_est","text":"","code":"penalized_est(   x,   w,   pen_par_id = NULL,   pen_diff_id = NULL,   pen_fn = \"l0a\",   pen_gr = NULL,   se = \"none\",   opt_control = list() )"},{"path":"https://marklhc.github.io/plavaan/reference/penalized_est.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Penalized Parameter Estimation for Longitudinal CFA Models — penalized_est","text":"x fitted lavaan model object estimation components extracted. w Numeric scalar. Penalty weight (multiplier) applied penalty terms. pen_par_id Integer vector parameter IDs apply penalty function directly , order returned lavaan::coef() lavaan::partable(), free elements. pen_diff_id List matrices containing parameter IDs. matrix, penalty applied pairwise differences parameters column indicated IDs. matrices names starting \"loading\", log transformation applied computing differences. pen_fn character string (\"l0a\" \"alf\") function computes penalty. Default \"l0a\". pen_gr function computes gradient penalty function. pen_fn \"l0a\" \"alf\", automatically set. se Character string specifying type standard errors compute. Options \"none\" (default; standard errors) \"robust.huber.white\" (robust sandwich estimator using numerical Hessian first-order information, used \"mlr\" estimator). opt_control list control parameters passed stats::nlminb(). Default includes eval.max = 2e4, iter.max = 1e4, abs.tol = 1e-20.","code":""},{"path":"https://marklhc.github.io/plavaan/reference/penalized_est.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Penalized Parameter Estimation for Longitudinal CFA Models — penalized_est","text":"lavaan model object updated penalized parameter estimates. returned object includes attribute opt_info containing optimization information returned nlminb().","code":""},{"path":"https://marklhc.github.io/plavaan/reference/penalized_est.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Penalized Parameter Estimation for Longitudinal CFA Models — penalized_est","text":"function uses nlminb() minimize penalized objective function combines standard lavaan objective function penalty term. parameter estimates log-likelihood interpreted. returned object \"fitted\" (.fit = FALSE) avoid users interpreting standard errors, generally valid penalized estimation. degrees freedom may also inaccurate. optimization converge (convergence code != 0), warning issued.","code":""},{"path":"https://marklhc.github.io/plavaan/reference/penalized_est.html","id":"warning","dir":"Reference","previous_headings":"","what":"Warning","title":"Penalized Parameter Estimation for Longitudinal CFA Models — penalized_est","text":"returned object fitted using standard ML. Standard errors reported summary() parameterEstimates() missing unless se = \"robust.huber.white\" specified. Even , based experimental sandwich approximation interpreted caution.","code":""},{"path":[]},{"path":"https://marklhc.github.io/plavaan/reference/penalized_est.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Penalized Parameter Estimation for Longitudinal CFA Models — penalized_est","text":"","code":"if (FALSE) { # \\dontrun{ library(lavaan)  # Fit a longitudinal factor model using PoliticalDemocracy data ind_mat <- cbind(c(\"y1\", \"y2\", \"y3\", \"y4\"), c(\"y5\", \"y6\", \"y7\", \"y8\")) fit <- longcfa(ind_mat, lv_names = c(\"dem60\", \"dem65\"), data = PoliticalDemocracy,                long_equal = c(\"loadings\", \"intercepts\"), lag_cov = TRUE) # Obtain an unidentified model mod_un <- longcfa_syntax(     ind_mat, lv_names = c(\"dem60\", \"dem65\"),     lag_cov = TRUE,     free_latvars = TRUE, free_latmeans = TRUE ) fit_un <- cfa(mod_un, data = PoliticalDemocracy, do.fit = FALSE, std.lv = TRUE,               start = fit)  # Get parameter IDs for loadings load_ids <- get_lav_par_id(fit_un, op = \"=~\", ind_matrix = ind_mat) int_ids <- get_lav_par_id(fit_un, op = \"~1\", ind_matrix = ind_mat)  # Apply penalized estimation with alignment loss pen_fit <- penalized_est(     x = fit_un,     w = 0.1,     pen_diff_id = list(cbind(t(load_ids), t(int_ids))),     pen_fn = \"alf\" )  # Compare parameter estimates cbind(coef(fit), coef(pen_fit))  # Compare log-likelihoods c(\"scalar invariance\" = logLik(fit), \"penalized\" = logLik(pen_fit)) } # }"}]
